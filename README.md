# AI Companion App

<div align="center">

![AI Companion](https://img.shields.io/badge/AI-Companion-blue)
![Next.js](https://img.shields.io/badge/Next.js-13-black)
![TypeScript](https://img.shields.io/badge/TypeScript-5.1-blue)
![LangChain](https://img.shields.io/badge/LangChain-0.0.92-green)

**Build conversational AI companions with personality, memory, and context-aware responses**

[Features](#-features) â€¢ [Demo](#live-demo) â€¢ [Quick Start](#-quick-start) â€¢ [Architecture](#system-overview)

</div>

---

## ğŸ“– Overview

AI Companion App is a production-ready, full-stack template for building customizable AI chatbots with persistent memory and dynamic personalities. Each companion maintains conversational context through vector similarity search and chat history, enabling more natural and engaging interactions.

### What Makes This Different?

- **ğŸ­ Unique Personalities** - Define characters with custom backstories, behaviors, and conversational styles
- **ğŸ§  Contextual Memory** - Vector database integration enables semantic recall of relevant information
- **ğŸ’¬ Multi-Model Support** - Switch between OpenAI GPT, Llama2, Vicuna, or custom LLM providers
- **ğŸ“± Multi-Channel** - Chat via web interface or SMS (Twilio integration)
- **ğŸ”’ Enterprise Auth** - Secure authentication with Clerk
- **âš¡ Real-time Streaming** - Instant response streaming for better UX

---

## âœ¨ Features

### Core Capabilities

| Feature | Description |
|---------|-------------|
| **Character System** | Define unlimited AI companions with text-based configuration files |
| **Vector Memory** | Semantic search through Pinecone or Supabase pgvector |
| **Chat History** | Persistent conversation storage via Upstash Redis |
| **Streaming Responses** | Real-time token streaming using Vercel AI SDK |
| **Rate Limiting** | Built-in protection against abuse (10 req/10s) |
| **Multi-modal Output** | Support for text, images, audio, and video responses |
| **SMS Integration** | Text your AI companion via Twilio (optional) |
| **Export Functionality** | Export chat history to Character.AI format |

### Supported LLM Providers

- âœ… **OpenAI** (GPT-3.5-turbo-16k, GPT-4)
- âœ… **Replicate** (Llama2-13b, Vicuna-13b)
- âœ… **Steamship** (Custom agents)
- ğŸ”§ **Extensible** - Easy to add new providers

---

## Live Demo
```bash
# Try it yourself
npm run dev
# Navigate to http://localhost:3000
```

## ğŸš€ Quick Start
### Prerequisites

Node.js 18.x or higher
```bash
npm or yarn
```
API keys for services you plan to use (see Environment Setup)

### Installation
### Clone the repository
```bash
git clone https://github.com/yourusername/ai-companion-app.git
cd ai-companion-app
```

### Install dependencies
```bash
npm install
```
### Copy environment template
```bash
cp .env.local.example .env.local
```
### Configure your environment variables (see below)
### Environment Setup
Create a .env.local file with the following variables:
### Vector Database (choose one)
```bash
VECTOR_DB= 'pinecone'  or 'supabase'
```
### Authentication (Clerk)
```bash
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_****
CLERK_SECRET_KEY=sk_****
NEXT_PUBLIC_CLERK_SIGN_IN_URL=/sign-in
NEXT_PUBLIC_CLERK_SIGN_UP_URL=/sign-up
NEXT_PUBLIC_CLERK_AFTER_SIGN_IN_URL=/
NEXT_PUBLIC_CLERK_AFTER_SIGN_UP_URL=/
```
### LLM Providers
```bash
OPENAI_API_KEY=sk-****
REPLICATE_API_TOKEN=r8_****
```

### Vector Database (Pinecone)
```bash
PINECONE_API_KEY=****
PINECONE_ENVIRONMENT=us-****
PINECONE_INDEX=****
```
### OR Vector Database (Supabase)
```bash
SUPABASE_URL=https://****
SUPABASE_PRIVATE_KEY=****
```
### Chat History (Upstash Redis)
```bash
UPSTASH_REDIS_REST_URL=https://****
UPSTASH_REDIS_REST_TOKEN=****
```

### Optional: SMS Support (Twilio)
```bash
TWILIO_ACCOUNT_SID=AC****
TWILIO_AUTH_TOKEN=****
```

### Optional: Steamship Agents
```bash
STEAMSHIP_API_KEY=****
```

## Generate Vector Embeddings
Before running the app, generate embeddings for your character backstories:
### For Pinecone
```bash
npm run generate-embeddings-pinecone
```

### For Supabase
```bash
npm run generate-embeddings-supabase
```

## Run Development Server
```bash
npm run dev
```

## ğŸ—ï¸ Architecture
### System Overview
<img width="419" height="286" alt="image" src="https://github.com/user-attachments/assets/c6f9a51a-11e5-4d6a-84df-4ac06e4e0278" />


## Data Flow

1. User sends message â†’ Authenticated via Clerk
2. Rate limiting check â†’ Upstash Redis
3. Retrieve chat history â†’ Last 30 messages from Redis
4. Vector similarity search â†’ Relevant backstory chunks from Pinecone/Supabase
5. Construct prompt â†’ Combine personality + history + context
6. LLM inference â†’ Stream response from chosen provider
7. Store message â†’ Save to Redis for future context

## Key Components
```bash
src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ chatgpt/route.ts       # OpenAI integration
â”‚   â”‚   â”œâ”€â”€ llama2-13b/route.ts    # Replicate Llama2
â”‚   â”‚   â”œâ”€â”€ vicuna13b/route.ts     # Replicate Vicuna
â”‚   â”‚   â”œâ”€â”€ steamship/route.ts     # Steamship agents
â”‚   â”‚   â””â”€â”€ text/route.ts          # Twilio SMS handler
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ memory.ts              # Vector DB & Redis manager
â”‚   â”‚   â”œâ”€â”€ config.ts              # Configuration loader
â”‚   â”‚   â””â”€â”€ rateLimit.ts           # Rate limiting logic
â”‚   â””â”€â”€ page.tsx                   # Landing page
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ Examples.tsx               # Character gallery
â”‚   â”œâ”€â”€ QAModal.tsx                # Chat interface
â”‚   â”œâ”€â”€ ChatBlock.tsx              # Multimodal message rendering
â”‚   â””â”€â”€ Navbar.tsx                 # Navigation bar
â””â”€â”€ companions/
    â”œâ”€â”€ companions.json            # Character configurations
    â”œâ”€â”€ Alex.txt                   # Character definition files
    â”œâ”€â”€ Evelyn.txt
    â””â”€â”€ ...
```



