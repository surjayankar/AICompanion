# AI Companion App  

The **AI Companion App** is a full-stack template for building customizable AI companions that you can chat with directly in the browser.  

Each companion has its own **personality, backstory, and memory**, allowing for more natural and engaging conversations. The system uses a **vector database** for contextual recall, enabling companions to reference details from previous interactions or their defined backstory.  

---

## âœ¨ Key Features  

- **Multiple AI Companions** â€“ define as many unique characters as you want  
- **Custom Personalities** â€“ control behavior, tone, and backstory through simple text files  
- **Conversational Memory** â€“ stores chat history for richer, more contextual dialogue  
- **Vector Database Integration** â€“ powered by Supabase pgvector for semantic search  
- **Choice of LLMs** â€“ fast and reliable responses from OpenAI or more dynamic interactions with Replicateâ€™s Vicuna  
- **Authentication & User Management** â€“ secured with Clerk  
- **Modern Web Stack** â€“ Next.js frontend with LangChain.js for orchestration  

---

## ğŸ› ï¸ Tech Stack  

- **Frontend & App Logic** â†’ Next.js  
- **Authentication** â†’ Clerk  
- **Vector Database** â†’ Supabase (pgvector)  
- **Conversation History** â†’ Upstash (Redis)  
- **LLM Orchestration** â†’ LangChain.js  
- **Models Supported** â†’ OpenAI GPT, Replicate (Vicuna13b)  

---

## ğŸ“– How It Works  

1. **Character Definition** â€“ Each companion has a description, seed conversation, and backstory stored in the project.  
2. **Embeddings** â€“ Character data is embedded and stored in Supabase pgvector.  
3. **Conversation Flow** â€“ LangChain retrieves relevant memory and backstory, then builds prompts for the chosen LLM.  
4. **Chat Interface** â€“ A clean Next.js interface lets users talk to companions in real time.  

---

## ğŸš€ Use Cases  

- AI friends & social chatbots  
- Storytelling and creative writing partners  
- Coaching or educational companions  
- Entertainment and roleplay  
- Experimentation for developers learning about LLM apps  

---

## âš ï¸ Limitations  

- Only the most recent chat is displayed in the UI (conversation history is stored but not fully visualized)  
- Vicuna responses can be slow due to cold start times  
- Error handling is minimal (timeouts may fail silently)  
- Conversation history in Upstash must be cleared manually  

---

 
